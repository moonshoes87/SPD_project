

  #      self.pars['magic_method_codes']=Data[self.s]['pars']['magic_method_codes']                           
        # for some reason missing any magic_method_codes.  possibly these would have been incorporated into the data from rmag_anisotr
opy or something                                                                                                                     
    # magic_method codes are locked up in datablock, not actually extracted.  not sure if this happens somewhere else in thellier_\
gui or not                                         
There's some stuff in the code like:

        for rec in self.Data[self.s]['datablock']:
          if "LT-NO" in rec['magic_method_codes']:
              nrm0= "%.2e"%float(rec['measurement_magn_moment'])
              break

But nowhere do the magic_method codes get pulled out and organized
                                                                             
        # also, fix the weirdness of having to set the precise number for tmin and tmax    

       

The temperature selector bar thing is in kelvin, but tmin, tmax are in C.  hahahahaha.  

don't forget array behavior options (linspace, arange, etc.)

in lj_thellier_gui_spd

added this into get_data()
self.s = self.specimens[0]  # LORI WEIRD ADDITION 




read_magic_file()
  Neither does anything for me currently.  

  # read_magic_file takes 2 args.  not a class method.  
      currently called for: er_ages, er_specimens, and er_samples
  # (renamed) classy_read_magic_file takes 4 args (including self).  is class method.
      currently called only for pmag_specimens



get_data() calls:

read_magic_file()

def get_specs(self,data):

read_magic_file() returns data from a magic_measurements file that looks like this:

magic file: /Users/nebula/Python/SPD_project/magic_measurements.txt
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
	  returns a dictionary and a string

def get_specs(self,data):
        """                                                                                                                            
         takes a magic format file and returns a list of unique specimen names                                                         
        """






>>> import new_lj_thellier_gui_spd as tgs
>>> gui = tgs.Arai_GUI()
 calling __init__ Arai_gui instance
calling get_default_criteria()
calling read_criteria_from_file
calling get_default_criteria()
calling get_data_info()
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_samples.txt
-W- Cant find er_sample.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_sites.txt
-W- Cant find er_sites.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
-W- Cant find er_ages in project directory

arai_GUI initialization calling self.get_data()
calling get_data()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
-I- Read magic file  /Users/nebula/Python/SPD_project/magic_measurements.txt

calling get_specs()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_anisotropy.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_results.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

-I- Done calculating non linear TRM parameters for all specimens
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
-I- number of specimens in this project directory: 6

-I- number of samples in this project directory: 2

returning Data, data_hierarchy.  This is the completion of self.get_data().  printing Data['0238x5721062']
{'x_ptrm_check_starting_point': .....
done with get_data
calling get_previous_interpretation()
-I- Read pmag_specimens.txt for previouse interpretation
calling read magic file in thellier_gui_spd_lj.py
/Users/nebula/Python/SPD_project/pmag_specimens.txt
data info:  {'er_sites': {}, 'er_samples': {}, 'er_ages': {}} # last print call in gui __init__
>>>




pTRM check -- going back to a cooler temperature to see if specimen still has the same capacity to take on pTRM, or if it has been altered
pTRM tail check -- ?? assess if pTRM gained at x temp is completely removed by reheating to the same temperature.  why does this one matter??




methods had by the average specimen:
METHODS ['LT-T-I', 'LP-PI-TRM-ZI', 'LP-PI-TRM', 'LP-PI-ALT-PTRM', 'LP-PI-BT-MD', 'LP-PI-BT-IZZI']
METHODS ['LT-PTRM-MD', 'LP-PI-TRM', 'LP-PI-ALT-PTRM', 'LP-PI-BT-MD', 'LP-PI-BT-IZZI']

tgs.thing1.pars['magic_method_codes'], tgs.thing2.pars['magic_method_codes']
('LP-PI-BT-IZZI:IE-TT:LP-PI-ALT-PTRM:LP-PI-BT-MD', 'LP-PI-ZI:IE-TT:LP-PI-ALT-PTRM')



magic method codes:

LT-T-I	     Lab Treatment	Specimen cooling: In laboratory field

LP-PI-TRM    Lab Protocol		  	  Paleointensity experiment: Using a laboratory TRM. Any paleointensity experiment that uses a TRM produced in a lab controlled field. Includes all variants of the Thellier method, including the Shaw method. More details on alteration and reciprocity checks can be added using the special LP-PI-ALT and LP-PI-BT method codes. Thellier 1938.

LP-TRM	     Lab Protocol			 TRM acquisition.

LT-M-I	     Lab Treatment			Using microwave radiation: In laboratory field. Walton et al. 1993.

LP-PI-M	     Lab Protocol		       	Paleointensity experiment: Microwave demagnetization. 

LT-NO	     Lab Treatment			No treatments applied before measurement.

LT-T-Z	     Lab Treatment			Specimen cooling: In zero field. Heating the specimen to the desired temperature step and then cooling in zero ambient magnetic field. Wilson 1961, Collinson 1983.

LT-M-Z	     Lab Treatment			Using microwave radiation: In zero field. Walton et al. 1992.

LT-PTRM-Z    Lab Treatment			pTRM tail check After in laboratory field step, perform a zero field cooling at a lower temperature. After heating to a particular temperature step and cooling in field. The specimen is heated to a lower temperature step and cooled in zero field. This checks for low temperature pTRM tails. Harcombe-Smee et al. 1996.

LT-PTRM-I    Lab Treatment			 pTRM check: After zero field step, perform an in field cooling. After treatment at a particular temperature step, the specimen is then reheated to a lower temperature and cooled with the laboratory field on thus reapplying a pTRM. Coe 1967.

LT-PTRM-MD   Lab Treatment			       	     pTRM tail check: After in laboratory field step, perform a zero field cooling at same temperature. A check carried out during Thellier procedures to detect multidomain grains. Additional zero field heating steps are used to remove a previously placed pTRM. The ability to remove a prior pTRM step at the same temperature imparted is used as an indicator of reversal. Riisager & Riisager 2001, Scherbakov et al. 1993.




to do:

check get_curve()
      determine whether norming should or should not be done
ask Alex about last bit of VDS calculation
maybe return to delta_pal, although I think it is working
documentation
return to thellier_gui_spd editing.  definitely will want to rename, probably prune some unnecessary code
maybe go through stats one at a time, checking them against their definition?  but really, probably it's better just to get matlab
consider adding in a params checker so that you can actually run one statistic only.  or, run the stats in groups (by chapter)
problem with DRATS statistic.  maybe just because of the slightly different method of selecting ptrm checks in thellier_gui vs. spd.  inconsistency with specimen MGH1 # confirmed as suspected
check that new set of specimens are basically working correctly # DONE
AC checks now available in specimen_Data, however must attend to tmax
check for missing stats



cart2dir
	require x,y,z
dir2cart
	works with just Dec, Inc
	however, outputs very different value if given Dec, Inc, and m (or whatever)  magnitude is different
	dir2cart(Dec, Inc, 1) --> x,y,z
	dir2cart(Dec, Inc, 2) --> 2x,2y,z
	

thellier_gui Dec, Inc, and MAD are free.  lisa always uses free
matlab SVD and numpy SVD produce nearly, but not exactly, identical output.  difference is in V, and also in the format for S (less important) # seems to be a rounding issue only
Also, checked and numpy and matlab notation for slicing is the same, except that matlab indexing starts at 1, not 0



meeting with lisa:

need to figure out how we're doing testing.  I know matlab basic syntax now, but will need help parsing data to feed it into his code.  

architecture and use scenarios
	     paramater checking, to enable running just one statistic (with its dependencies)

abstracting out the parsing portion of thellier_gui_spd further




new meeting notes:

from greig's code:  % ChRM          - a (1 x 2) or a (1 x 3) vector describing an independent measure of the direction of Banc (can be a known direction).
this would make one of my stats wrong.  

how to do additivity

which chapter to stop at??



for meeting with Ron:

norming of points in curvature.  are they already normed?  I guess it just matters for magnitude


	This from thellier_gui is in contradiction to what's in spd.  this sometimes causes different results for pTRM check statistics
          # If triangle is within the interval but started after the upper temperature bound, then one pTRM check is in
cluded                                                                                                               
          # For example: if T_max=480, the traingle in 450 fall far, and it started at 500, then it is included  
          # the ateration occured between 450 and 500, we dont know when. 



delta_pal.  really pays no attention to tmin, just tmax?  weird.  check this.



projects for these times when you are missing information to actually work on your current project:

	 study Python
	 wx Python tutorial...(?) or possibly look at other gui frameworks
	 improve new_lj_thellier_gui_spd.  at least rename.
	 write a utility file that runs through all the tests....?  maybe this is unnecessary, though
	 remove unnecessary output for all files


to run all tests:

$  python -m unittest test_arai_plot_statistics test_directional_statistics test_curvature test_ptrm_statistics test_tail_check_statistics test_additivity_check_statistics



Python tips and tricks:

dir(spd) -- gives all methods/classes available in spd.  awesome.  

pop, remove, and del -- useful stuff for lists

*args

if changing a list in your loop, it's better to iterate through indices.  i.e, for i in range(len(list)), vs for i in list

" ".join(row)

list comprehensions --- [x**2 for x in range(10)]

filter() # takes two args, function and iterable.  works well with lambda.

lambda

overriding built in methods -- i.e., __repr__(), which determines how an object prints

you can use *args thusly:  
    a = [1,5]
    range(*a)


to use a list as a queue, use collections.dequeue, to grab off elements from the beginning of a list.  (for using a list as a stack, you can efficiently use append() and pop())

use regex





Notes for matlab:

struct is a dictionary(ish)
displays like this:
Params = 

               Xpts: [8x1 double]
               Ypts: [8x1 double]

called like this:
Params.Xpts


Think I sould make a script to write Params in an orderly manner to a tab-delimited file for easy comparison with 

cell array is similar to a Python list.  

my_struct = struct('a', 'b', 'c', 4)
	  a: b
	  c: 4
a = 'x'
my_struct.(a) == my_struct.x
my_struct.a == my_struct.a
isfield(my_struct, 'a') == 1 
fieldnames(my_struct) == [a, c]
orderfields, rmfields



my_cell = struct2cell(my_struct)
	'b'
	4



my_fieldnames = fieldnames(my_struct)
	      a
	      c


Restore data from a MAT-file into the workspace using load.  load myfile.mat.  also save myfile.mat puts workspace variables into a file


num2str -- number to string, obviously.  also int2str

my_cell(1) != my_cell{1}

my_cell(1) is a cell object of length one.  my_cell{1} is the first item	


next steps:
modify the read tdt program to be able to do more at one time
       probably best not to write to individual file, but all pile into one
check into data norming -- may be causing some of the discrepancies
maybe reduce rounding of greig's stuff so that you can do a more rigorous comparison.  
      rounding is all at line 1290 of getPintParams_v5c.m
the way comparisons work currently is if I only have one specimen and one sample with one specimen.  endeavering to fix that in lori_Read_TDT.m
    ./comp_files.py -f1 ET1_Biggin_2007_output_first.txt -f2 ~/Documents/MATLAB/new_out.out 
    works when only the BS file is available in the Data folder
    problem with the list in a list thing.  meh.
            removing the list in a list.  I don't have a comparison for it, anyway.




questions for Ron, next meeting:

pmag_criteria.txt
norming.... is this causing some of my problems?
some details about format of .tdt files


I can find equivalent dec/inc data in the magic measurements vs. .tdt files, but I can't find intensity or magnetic moment data that lines up. 


dir2cart function is the same in lib and in GetPintParams.tdt.  Except that Greig's version returns only the first number of the cartesian coordinates.  (dir2cart is called in both programs to convert [dec, inc, int])


    zdata difference:

    % Convert to x, y, z and put into Mvec
    Mvec=NaN(length(Int), 3); %Create an empty matrix
    [Mvec(:,1), Mvec(:,2), Mvec(:,3)]=dir2cart(Dec, Inc, Int);

    % then NRMvec just grabs without changing the appropriate (zerofield) values


    # in thellier_gui_spd, it is essentially the same BUT it does dir2cart([dec, inc, int / NRM]). 
#NRM=zijdblock[0][3]
#for k in range(len(zijdblock)):
 #           DIR=[zijdblock[k][1],zijdblock[k][2],zijdblock[k][3]/NRM]
  #          cart=self.dir2cart(DIR)
   #         zdata.append(array([cart[0],cart[1],cart[2]]))


    This makes zdata quite challenging to compare.  

    FRAC --  it sums zdata diffs and divides by vds

    His NRMvec(1,:) / Int(1) == my zdata[0]
    NRMvec(2,:) / Int(1) == my zdata[1]

    But the actual cause of the difference: he takes all but the last diff:  ...diff(NRMvec(seg_min:seg_max - 1,2:end)...

    My FRAC agrees with thellier_gui FRAC


how x points are attained in tgs:
    [temp, dec, inc, int, other]
    int is grabbed (magnetic intensity) from the infield data points, and normed by the original NRM of the untouched sample.
    dir2cart([dec, inc, int])
y points: 
  same, but with zerofield data points.

problems and solutions:

solved:

B_anc -- off by a factor of 6.   3.05933660143e-05 vs. 30.6
B_anc sigma -- same
x_pts -- My SPD norms by NRM; Greig's does not
y_pts -- My SPD norms by NRM; Greig's does not
Y_int  ---  same
x_int ---  same
GAP_MAX -- my code norms by partial_vds, Greig's by full vds.  have changed this.  (mine & Ron's agree) CHANGED BACK
       # GAP_MAX = max_diff / vds -- Greig's
       # GAP_MAX = max_diff / partial_vds -- correct
FRAC --- Greig's code does not take the final diff.  now mine doesn't either.  fixed.
many things breaking with taking different tmin, tmax -- my code uses x/y_segment to get x/y_prime.  Greig's uses full set of x/y points.
     -- GO BACK TO THIS.... need to be SURE.  Ron confirmed that it is the same calculation in his code and in spd document.  
     -- this seems not to be true.  delta_y_prime is ok
IZZI_MD -- going to Greig to fix his code
NRM_dev:
        radians vs degrees problem.  FIXED
max_DEV:
        once was lost, now is found


unsolved:

update:  need to test with an IZZI type experiment.  for now, I don't have any in tdt format.  But that is ok.

IZZI_MD -- believe will put IZZI_MD into its own module.  it's big. 
        it's all   ['ZI', 'ZI', 'ZI', 'ZI', 'ZI', 'ZI', 'ZI'] in the new specimens.  in this case, it fails on the get_triangles segment.

        My IZZI_MD and Ron's are not the same.  I think I will just use Ron's.  
        But still, Ron's fails on specimen 'ET1_318A', where Greig's produces output.

        In Greig's code, Treatment -- 0 = ZI, 1 = IZ, etc...

        for all of the Biggin specimens, I get only ZI steps.  however, the araiblock has: 
                araiblock=(first_Z,first_I,ptrm_check,ptrm_tail,zptrm_check,GammaChecks,additivity_check)
                so, how does the araiblock get turned into steps arai?

         in tgs:
          first sortarai()      
         then (zerofields = araiblock[0], infields = araiblock[1] ):

               if "LP-PI-TRM-IZ" in methcodes or "LP-PI-M-IZ" in methcodes:
                    ZI=0
                else:
                    ZI=1

         LP-PI-TRM-IZ:  Paleointensity experiment: Using a laboratory TRM with an in-field step followed by a zero-field step. Heating the specimen to the desired temperature step and then cooling in known ambient magnetic field. Then heating to the same or lower temperature and then cooling in zero magnetic nfield to induce pTRM.
         LP-PI-M-IZ:  Same-ish but with microwave

          if zerofields[k][4]==1:
            steps_Arai.append('ZI')
          else:
            steps_Arai.append('IZ')

      # looking for Thellier Thellier protocol
      if 'LP-PI-II'in methcodes or 'LP-PI-T-II' in methcodes or 'LP-PI-M-II' in methcodes:  
      ....
            first_Z.append([temp,DIR_zerofield[0],DIR_zerofield[1],DIR_zerofield[2],0])
            first_I.append([temp,DIR_infield[0],DIR_infield[1],DIR_infield[2],0])

  Neither condition which would trigger ZI to be 0 is ever getting met.  In other words: in magic_measurements, the method codes for IZ step are not being found.  In the tdt files, there are clear IZ steps.  
  Also, cross-checked with Lisa's thellier_magic, which also didn't grab any IZ points (only closed red circles in graph, no blue)

        in read_tdt:
           ET1_318A    150.1   6.457964075 214.5410563 -10.52823962
           treatment is:   1 
           etc. (0 is ZI, 1 is IZ, etc.)




  


Possibly a totally fucked up indexing temperature system.  Greig uses: ...start point, end point...  vs. tmin, tmax


theta:
        B_lab vector disagrees.  must talk to Ron.
        also, for ChRM value, Greig uses equivalent to my best_fit_vector_Anc, whereas I've been using best_fit_vector_Free.
gamma:
        also has B_lab problem.  UPDATE: this is now the only problem
        his TRMvec / NRM == my dir2cart([PTRMS[i][1], PTRMS[i][2], PTRMS[i][3] / NRM])
        (in gamma):       my ptrm_cart == his Params.TRMvec(seg_max,2:end) / NRM  (now.  so that's good).  (This is the vector edition of the max pTRM)
mean_DRAT_prime:
delta_pal:
        his TRMvec / NRM == my dir2cart([PTRMS[i][1], PTRMS[i][2], PTRMS[i][3] / NRM])
        his pCheck / NRM == my dir2cart([PTRM_Checks[i][1], PTRM_Checks[i][2], PTRM_Checks[i][3] / NRM])
        his to_sum / NRM == my diffs
        his dpal_sum / NRM == my numpy.cumsum(diffs, 0) == my C
        his corr_TRM / NRM == my x_star
        his delta_pal now == my delta_pal!!!!





to do now:
   check about vds and which diffs are included
   return to NRM_dev, etc.




different possible units for magnetic moment:

mKs.  meter Kelvin seconds.  measurement unit for magnetic moment.  used in magic measurements format.

should be normed by first NRM (full, pre-experiment)

.tdt uses different measurement.  if b (slope) is the same, then it's fine.

be careful with v. large or v. small numbers.  float, long, etc.  this can be significant.  


Don't forget you will need to test everything with EVERY possible set of temperature bounds

problem with GAP-MAX.  Greig uses raw data from the tdt files, which uses a different form for magnetic moment.  
tdt -- uses milliamp / meter
magic -- uses meter Kelvin seconds





style notes:
      stop using tabs!  spaces!
