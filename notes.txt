                                                                             


read_magic_file()
  Neither does anything for me currently.  

  # read_magic_file takes 2 args.  not a class method.  
      currently called for: er_ages, er_specimens, and er_samples
  # (renamed) classy_read_magic_file takes 4 args (including self).  is class method.
      currently called only for pmag_specimens



get_data() calls:

read_magic_file()

def get_specs(self,data):

read_magic_file() returns data from a magic_measurements file that looks like this:

magic file: /Users/nebula/Python/SPD_project/magic_measurements.txt
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
	  returns a dictionary and a string

def get_specs(self,data):
        """                                                                                                                            
         takes a magic format file and returns a list of unique specimen names                                                         
        """




>>> import new_lj_thellier_gui_spd as tgs
>>> gui = tgs.Arai_GUI()
 calling __init__ Arai_gui instance
calling get_default_criteria()
calling read_criteria_from_file
calling get_default_criteria()
calling get_data_info()
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_samples.txt
-W- Cant find er_sample.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_sites.txt
-W- Cant find er_sites.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
-W- Cant find er_ages in project directory

arai_GUI initialization calling self.get_data()
calling get_data()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
-I- Read magic file  /Users/nebula/Python/SPD_project/magic_measurements.txt

calling get_specs()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_anisotropy.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_results.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

-I- Done calculating non linear TRM parameters for all specimens
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
-I- number of specimens in this project directory: 6

-I- number of samples in this project directory: 2

returning Data, data_hierarchy.  This is the completion of self.get_data().  printing Data['0238x5721062']
{'x_ptrm_check_starting_point': .....
done with get_data
calling get_previous_interpretation()
-I- Read pmag_specimens.txt for previouse interpretation
calling read magic file in thellier_gui_spd_lj.py
/Users/nebula/Python/SPD_project/pmag_specimens.txt
data info:  {'er_sites': {}, 'er_samples': {}, 'er_ages': {}} # last print call in gui __init__
>>>




***** magic method codes: *****

LT-T-I	     Lab Treatment	Specimen cooling: In laboratory field

LP-PI-TRM    Lab Protocol		  	  Paleointensity experiment: Using a laboratory TRM. Any paleointensity experiment that uses a TRM produced in a lab controlled field. Includes all variants of the Thellier method, including the Shaw method. More details on alteration and reciprocity checks can be added using the special LP-PI-ALT and LP-PI-BT method codes. Thellier 1938.

LP-TRM	     Lab Protocol			 TRM acquisition.

LT-M-I	     Lab Treatment			Using microwave radiation: In laboratory field. Walton et al. 1993.

LP-PI-M	     Lab Protocol		       	Paleointensity experiment: Microwave demagnetization. 
 
LT-NO	     Lab Treatment			No treatments applied before measurement.

LT-T-Z	     Lab Treatment			Specimen cooling: In zero field. Heating the specimen to the desired temperature step and then cooling in zero ambient magnetic field. Wilson 1961, Collinson 1983.

LT-M-Z	     Lab Treatment			Using microwave radiation: In zero field. Walton et al. 1992.

LT-PTRM-Z    Lab Treatment			pTRM tail check After in laboratory field step, perform a zero field cooling at a lower temperature. After heating to a particular temperature step and cooling in field. The specimen is heated to a lower temperature step and cooled in zero field. This checks for low temperature pTRM tails. Harcombe-Smee et al. 1996.

LT-PTRM-I    Lab Treatment			 pTRM check: After zero field step, perform an in field cooling. After treatment at a particular temperature step, the specimen is then reheated to a lower temperature and cooled with the laboratory field on thus reapplying a pTRM. Coe 1967.

LT-PTRM-MD   Lab Treatment			       	     pTRM tail check: After in laboratory field step, perform a zero field cooling at same temperature. A check carried out during Thellier procedures to detect multidomain grains. Additional zero field heating steps are used to remove a previously placed pTRM. The ability to remove a prior pTRM step at the same temperature imparted is used as an indicator of reversal. Riisager & Riisager 2001, Scherbakov et al. 1993.


****end magic codes****



cart2dir
	require x,y,z
dir2cart
	works with just Dec, Inc
	however, outputs very different value if given Dec, Inc, and m (or whatever)  magnitude is different
	dir2cart(Dec, Inc, 1) --> x,y,z
	dir2cart(Dec, Inc, 2) --> 2x,2y,z
	



#####  Python tips and tricks:  #######

dir(spd) -- gives all methods/classes available in spd.  awesome.  

pop, remove, and del -- useful stuff for lists

*args

if changing a list in your loop, it's better to iterate through indices.  i.e, for i in range(len(list)), vs for i in list

" ".join(row)

list comprehensions --- [x**2 for x in range(10)]

filter() # takes two args, function and iterable.  works well with lambda.

lambda

overriding built in methods -- i.e., __repr__(), which determines how an object prints

you can use *args thusly:  
    a = [1,5]
    range(*a)


to use a list as a queue, use collections.dequeue, to grab off elements from the beginning of a list.  (for using a list as a stack, you can efficiently use append() and pop())

use regex

>>> try:
...     1/0
... except:
...     print "exception"
... else:
...     print "else"
... finally:
...     print "finally"
... 
exception
finally


os.getcwd()
returns working directory, yay!

python -i module
runs module then goes into interactive mode, so you can find end values of variables, play around, etc.  

list comprehensions
     comprehensions also work for dictionaries, sets, and generators:
>>> r = range(5)
>>> {i**2: i for i in r}
{0: 0, 1: 1, 4: 2, 16: 4, 9: 3}
>>> 



###### end python notes ######




###Notes for matlab:####

struct is a dictionary(ish)
displays like this:
Params = 

               Xpts: [8x1 double]
               Ypts: [8x1 double]

called like this:
Params.Xpts


Think I sould make a script to write Params in an orderly manner to a tab-delimited file for easy comparison with 

cell array is similar to a Python list.  

my_struct = struct('a', 'b', 'c', 4)
	  a: b
	  c: 4
a = 'x'
my_struct.(a) == my_struct.x
my_struct.a == my_struct.a
isfield(my_struct, 'a') == 1 
fieldnames(my_struct) == [a, c]
orderfields, rmfields


my_cell = struct2cell(my_struct)
	'b'
	4


my_fieldnames = fieldnames(my_struct)
	      a
	      c

Restore data from a MAT-file into the workspace using load.  load myfile.mat.  also save myfile.mat puts workspace variables into a file

num2str -- number to string, obviously.  also int2str

my_cell(1) != my_cell{1}

my_cell(1) is a cell object of length one.  my_cell{1} is the first item	

##### end matlab notes #####



#### comparing my spd and Greig's spd #####

I can find equivalent dec/inc data in the magic measurements vs. .tdt files, but I can't find intensity or magnetic moment data that lines up. Update: this is because it's in different units

dir2cart function is the same in lib and in GetPintParams.tdt.  

    zdata difference:

    % Convert to x, y, z and put into Mvec
    Mvec=NaN(length(Int), 3); %Create an empty matrix
    [Mvec(:,1), Mvec(:,2), Mvec(:,3)]=dir2cart(Dec, Inc, Int);

    % then NRMvec just grabs without changing the appropriate (zerofield) values


    # in thellier_gui_spd, it is essentially the same BUT it does dir2cart([dec, inc, int / NRM]). 
#NRM=zijdblock[0][3]
#for k in range(len(zijdblock)):
 #           DIR=[zijdblock[k][1],zijdblock[k][2],zijdblock[k][3]/NRM]
  #          cart=self.dir2cart(DIR)
   #         zdata.append(array([cart[0],cart[1],cart[2]]))


    This makes zdata quite challenging to compare.  



how x points are attained in tgs:
    [temp, dec, inc, int, other]
    int is grabbed (magnetic intensity) from the infield data points, and normed by the original NRM of the untouched sample.
    dir2cart([dec, inc, int])
y points: 
  same, but with zerofield data points.

######### problems and solutions: #############

solved:

B_anc -- off by a factor of 6.   3.05933660143e-05 vs. 30.6
B_anc sigma -- same
x_pts -- My SPD norms by NRM; Greig's does not
y_pts -- My SPD norms by NRM; Greig's does not
Y_int  ---  same
x_int ---  same
GAP_MAX -- my code norms by partial_vds, Greig's by full vds.  believe mine is correct
       # GAP_MAX = max_diff / vds -- Greig's
       # GAP_MAX = max_diff / partial_vds -- correct
FRAC --- Greig's code does not take the final diff.  Greig will fix his.  
IZZI_MD -- going to Greig to fix his code
NRM_dev:
        radians vs degrees problem.  FIXED
max_DEV:
        once was lost, now is found
Z:
        should use segment, where I was using full data set.  fixed.
delta_y_prime, delta_x_prime -- using first and last values of x_prime/y_prime vs min and max 
        # DONE -- SPD document changed
r_det2 -- Greig uses full data, you use segment.  which is right?  Greig's was wrong.  should be fixed in next iteration of code.  
       # DONE -- Greig's code fixed

theta ---  whether to use best_fit_vector_Anc vs. free.  
                # DONE -- appears that Greig has switched to Free.  hoorah


 
Pending:

        δt∗  -- I have not coded this statistic
        problem in Greig's IZZI_MD, so he gets a value even when it is all IZ or ZI steps, not alternating.
                update:  need to test with an IZZI type experiment.  for now, I don't have any in tdt format.  But that is ok.
        problem with Greig's B_lab vector [0,0,-1] where should be [0,0,1]
        FRAC now disagrees with thellier_gui FRAC.  talk to Ron
        does my code need to be able to deal with someone selecting tmin = t[0], tmax = t[1] ?  Greig's produces output in this situation
        magic_measurements is missing one of the Biggin et al .tdt files.  probs no big deal. 
        
        delta_ck - Greig's code is different from SPD document.  Currently, I am in agreement with his code.  This is only an issue for some edge cases.   
                 #  DONE -- SPD document has been changed


       

current:

    GAP-MAX

    occasionally with fucked up data and the wrong of temperature bound, b is not in fact negative
    see: Bowles etal 200? AL3023_1b
    what to do about this?  should I be calculating b as Greig does?
         x_err = x_segment - x_mean
         y_err = y_segment - y_mean
         york_b = -1* sqrt( sum(y_err**2) / sum(x_err**2) )  # averaged slope 
         # how Greig does it:
         #Params.b=sign(sum(U.*V))*std(Y_seg)/std(X_seg);                                                   
         b = sign(sum(x_err * y_err)) * std(y_segment, ddof=1)/std(x_segment, ddof=1)
    ask Lisa


theta -- B_lab is different
gamma:
        also has B_lab problem.  UPDATE: this is now the only problem
        his TRMvec / NRM == my dir2cart([PTRMS[i][1], PTRMS[i][2], PTRMS[i][3] / NRM])
        (in gamma):       my ptrm_cart == his Params.TRMvec(seg_max,2:end) / NRM  (now.  so that's good).  (This is the vector edition of the max pTRM)
mean_DRAT_prime:
        ???
delta_pal:
        his TRMvec / NRM == my dir2cart([PTRMS[i][1], PTRMS[i][2], PTRMS[i][3] / NRM])
        his pCheck / NRM == my dir2cart([PTRM_Checks[i][1], PTRM_Checks[i][2], PTRM_Checks[i][3] / NRM])
        his to_sum / NRM == my diffs
        his dpal_sum / NRM == my numpy.cumsum(diffs, 0) == my C
        his xcorr / NRM == my x_star (both segment)
        here is the problem!!!  mine b_star is positive, his is negative       
        fixed corr_slope so that it is calculated correctly
        his corr_slope == my b_star
        his delta_pal now == my delta_pal!!!!


delta_AC:
        our AC_diffs are different.  (my spec.AC_diffs != his spec.AC)
        magic_measurements file does agree with .tdt file (dec/inc numbers line up for the add check steps)
        my add_check_starting_temps and add_check_temps == his spec.ADD_vec(:,1) and spec.ADD_vec(:,2)
        my n_add == his n_add
        this is the first data that actually uses additivity checks, so we don't have any specimens where our AC checks agree.
        # this is now mostly fixed
        

Ask Ron:
    precision in testing
    should I use Greig's rounding scheme?
    pmag_criteria.txt files....?  
    at very small temperature intervals, Ron's x_Arai differs from Greigs Xpts.  

    Matlab Xpts (normed):        v.      Python
   0.060244431120923                     0.0602445218843
   0.093109426319904                     0.0931094537109
   0.123564044710377                     0.123563866231

   In 3-4 out of 600 or so permutations, a few of the statistics ['Zstar:', 'NRM_dev:', 'delta_TR:', 'delta_AC:', 'Z:', 'specimen_w:', 'delta_CK:', 'specimen_q:'] will be slightly off.  i.e., w ==  42.0444353742 ----- 41.6691.  w & q seem to be the most prone. 
   This pretty much only happens when the temperature bounds are very tight (3 points).  I think this is due to the difference in calculation of x/y above.  Problem?  The difference between x point values is present even with specimens that produce correct results.  I think this lack of precision is ok...

    different AC values
              see email exchange



    B_lab_vector (see below)

    BR06 series, our B_lab_vectors disagree

        elseif (strcmp(files(f).name(1:3), 'HEL') || strcmp(files(f).name(1:3), 'BR0'))
            % +X-axis
            F_exp=49.6;
            F_orient=[1,0,0];
            Meth=1;    

        PintPars object, specimen: BR06-5F, tmin_K: 320.0, tmax_K: 410.0 
        >>> spec.B_lab_dir
        [0.0, 90.0, 5.025e-05]
        >>> lib.dir2cart(spec.B_lab_dir)
        array([  3.076925082857725e-21,   0.000000000000000e+00,
         5.025000000000000e-05])
         0, 0, .00005025







working examples:
Biggin etal -- 0 bad stats in 267 specimens
Bowles etal -- ~20 bad stats in 6416 specimens
Donadini etal -- theta and gamma wrong (BR0 series, Greig has ).  234 specimens compared
Krasa etal -- ~10 bad stats in 605 specimens
Muxworthy etal -- 6 bad stats in 3826 specimens
Paterson etal -- lots of bad stats.  COME BACK TO THIS ONE
Pick Tauxe -- 2 bad stats in 1632 specimens
Selkin et al -- big problem with B_anc
Tanaka etal -- 0 bad stats in 198 specimens
Yamamoto etal -- same as Donadini.  theta and gamma wrong, because of how B_lab_orient is set.
Yamamoto part 2 -- same as above

troubleshooting Paterson:

    looking at specimen LV3B3:
        Dec/Inc is the same between matlab and python
    problem appears to be in Xpts/Ypts.  Subtle parsing differences result in a reasonable difference in many important statistics.
    somehow zdata & NRMvec are different.  How?
    dir2cart functions are the same.  

    in read_tdt (see also below for PintPars portion)
    if (strcmp(files(f).name(1:2), 'LV')) % Paterson Lascar
        % -Z-axis
        F_exp=24.0;
        Meth=1;
        flags.Rot=1;
        [N_orient(1), N_orient(2), N_orient(3)]=dir2cart(385.5, -18.7, 1);


troubleshooting Selkin etal:

    my B_anc agrees with thellier_gui.  however, Greig does a correction that produces a very different B_anc

    Greig does a correction (flags.Anis, flags.Rot) that I do not
    in read_tdt:
    elseif (strcmp(files(f).name(1:4), 'm428'))
        % +z-axis
        F_orient=[0, 0, 1];
        flags.Anis=1;
        flags.Rot=1;
        N_orient=F_orient;
        F_exp=25;
        Meth=1;

in GetPintPars:
% Get the paleointensity estimate
Params.b=sign(sum(U.*V))*std(Y_seg)/std(X_seg);
if A_corr==1 && NLT_corr==0
    Params.Banc = Blab * abs( Params.Anis_c*Params.b );
elseif A_corr==0 && NLT_corr==1
    Params.Banc = real( atanh( abs(Params.b) * tanh(NLT_hat(2)*Blab) ) / NLT_hat(2) );
elseif A_corr==1 && NLT_corr==1
    Params.Banc = real( atanh( abs(Params.Anis_c*Params.b) * tanh(NLT_hat(2)*Blab) ) / NLT_hat(2) );
else
    Params.Banc = abs(Params.b)*Blab;
end


















####  long term notes: ####
        if we want, at some point, to really speed of code, consider PyPy


##### Extra notes that might be useful again someday: #####

IZZI_MD -- believe will put IZZI_MD into its own module.  it's big. 
        it's all   ['ZI', 'ZI', 'ZI', 'ZI', 'ZI', 'ZI', 'ZI'] in the new specimens.  in this case, it fails on the get_triangles segment.

        My IZZI_MD and Ron's are not the same.  I think I will just use Ron's.  
        But still, Ron's fails on specimen 'ET1_318A', where Greig's produces output.

        In Greig's code, Treatment -- 0 = ZI, 1 = IZ, etc...

        for all of the Biggin specimens, I get only ZI steps.  however, the araiblock has: 
                araiblock=(first_Z,first_I,ptrm_check,ptrm_tail,zptrm_check,GammaChecks,additivity_check)
                so, how does the araiblock get turned into steps arai?

         in tgs:
          first sortarai()      
         then (zerofields = araiblock[0], infields = araiblock[1] ):

               if "LP-PI-TRM-IZ" in methcodes or "LP-PI-M-IZ" in methcodes:
                    ZI=0
                else:
                    ZI=1

         LP-PI-TRM-IZ:  Paleointensity experiment: Using a laboratory TRM with an in-field step followed by a zero-field step. Heating the specimen to the desired temperature step and then cooling in known ambient magnetic field. Then heating to the same or lower temperature and then cooling in zero magnetic nfield to induce pTRM.
         LP-PI-M-IZ:  Same-ish but with microwave

          if zerofields[k][4]==1:
            steps_Arai.append('ZI')
          else:
            steps_Arai.append('IZ')

      # looking for Thellier Thellier protocol
      if 'LP-PI-II'in methcodes or 'LP-PI-T-II' in methcodes or 'LP-PI-M-II' in methcodes:  
      ....
            first_Z.append([temp,DIR_zerofield[0],DIR_zerofield[1],DIR_zerofield[2],0])
            first_I.append([temp,DIR_infield[0],DIR_infield[1],DIR_infield[2],0])

  Neither condition which would trigger ZI to be 0 is ever getting met.  In other words: in magic_measurements, the method codes for IZ step are not being found.  In the tdt files, there are clear IZ steps.  
  Also, cross-checked with Lisa's thellier_magic, which also didn't grab any IZ points (only closed red circles in graph, no blue)

        in read_tdt:
           ET1_318A    150.1   6.457964075 214.5410563 -10.52823962
           treatment is:   1 
           etc. (0 is ZI, 1 is IZ, etc.)






Lisa next steps:

travis CI
github gui for fun help
integration with thellier_gui
wxpython magic_gui.py
pmag.py -- replace functions where appropriate (GetPintPars for start)
        talk to Ron, who has been mucking about in PintPars
cookbook documentation -- links to thellier gui, spd document, etc.
         how to get going with pmag.py
         import scripts already exist in various forms



lori to do:
     email dude about curvature statistics
     figure out how to package stuff correctly as a module
            problem is that top level directory is not in search path
            this is ok if you only always work in that directory (see pg. 707)
            alternatively, you can put it in your pythonpath, do a .pth file, or some such


steps within thellier_gui
      read over get_PI_parameters
      put spd_project in python path
      work spd into get_PI_parameters
      fix SCAT
