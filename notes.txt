

  #      self.pars['magic_method_codes']=Data[self.s]['pars']['magic_method_codes']                           
        # for some reason missing any magic_method_codes.  possibly these would have been incorporated into the data from rmag_anisotr
opy or something                                                                                                                     
    # magic_method codes are locked up in datablock, not actually extracted.  not sure if this happens somewhere else in thellier_\
gui or not                                         
There's some stuff in the code like:

        for rec in self.Data[self.s]['datablock']:
          if "LT-NO" in rec['magic_method_codes']:
              nrm0= "%.2e"%float(rec['measurement_magn_moment'])
              break

But nowhere do the magic_method codes get pulled out and organized
                                                                             
        # also, fix the weirdness of having to set the precise number for tmin and tmax    

       

The temperature selector bar thing is in kelvin, but tmin, tmax are in C.  hahahahaha.  

don't forget array behavior options (linspace, arange, etc.)

in lj_thellier_gui_spd

added this into get_data()
self.s = self.specimens[0]  # LORI WEIRD ADDITION 




read_magic_file()
  Neither does anything for me currently.  

  # read_magic_file takes 2 args.  not a class method.  
      currently called for: er_ages, er_specimens, and er_samples
  # (renamed) classy_read_magic_file takes 4 args (including self).  is class method.
      currently called only for pmag_specimens



get_data() calls:

read_magic_file()

def get_specs(self,data):

read_magic_file() returns data from a magic_measurements file that looks like this:

magic file: /Users/nebula/Python/SPD_project/magic_measurements.txt
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
	  returns a dictionary and a string

def get_specs(self,data):
        """                                                                                                                            
         takes a magic format file and returns a list of unique specimen names                                                         
        """






>>> import new_lj_thellier_gui_spd as tgs
>>> gui = tgs.Arai_GUI()
 calling __init__ Arai_gui instance
calling get_default_criteria()
calling read_criteria_from_file
calling get_default_criteria()
calling get_data_info()
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_samples.txt
-W- Cant find er_sample.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_sites.txt
-W- Cant find er_sites.txt in project directory

Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
Calling read_magic_file() in get_data_info
/Users/nebula/Python/SPD_project/er_ages.txt
-W- Cant find er_ages in project directory

arai_GUI initialization calling self.get_data()
calling get_data()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/magic_measurements.txt
magic data:
[{'treatment_ac_field': '0', 'treatment_dc_field_theta': '90', 'measurement_temp': '273', 'er_citation_names': 'This study', 'measurement_magn_moment': '2.01e-09', 'treatment_temp': '273', 'measurement_number': '1', 'measurement_standard': 'u', 'er_site_name': '0238x', 'er_sample_name': '0238x601104', 'treatment_dc_field_phi': '0', 'measurement_inc': '-8.8', 'er_location_name': '238', 'measurement_dec': '257.6', 'magic_experiment_name': '0238x6011043:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-MD:LP-PI-BT...
file_type magic_measurements
-I- Read magic file  /Users/nebula/Python/SPD_project/magic_measurements.txt

calling get_specs()
calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_anisotropy.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

calling magic_read(self, infile) /Users/nebula/Python/SPD_project/rmag_results.txt
-I- Anisotropy data read  /Users/nebula/Python/SPD_project/from rmag_anisotropy.txt

-I- Done calculating non linear TRM parameters for all specimens
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
calling sortarai()
-I- number of specimens in this project directory: 6

-I- number of samples in this project directory: 2

returning Data, data_hierarchy.  This is the completion of self.get_data().  printing Data['0238x5721062']
{'x_ptrm_check_starting_point': .....
done with get_data
calling get_previous_interpretation()
-I- Read pmag_specimens.txt for previouse interpretation
calling read magic file in thellier_gui_spd_lj.py
/Users/nebula/Python/SPD_project/pmag_specimens.txt
data info:  {'er_sites': {}, 'er_samples': {}, 'er_ages': {}} # last print call in gui __init__
>>>




pTRM check -- going back to a cooler temperature to see if specimen still has the same capacity to take on pTRM, or if it has been altered
pTRM tail check -- ?? assess if pTRM gained at x temp is completely removed by reheating to the same temperature.  why does this one matter??




methods had by the average specimen:
METHODS ['LT-T-I', 'LP-PI-TRM-ZI', 'LP-PI-TRM', 'LP-PI-ALT-PTRM', 'LP-PI-BT-MD', 'LP-PI-BT-IZZI']
METHODS ['LT-PTRM-MD', 'LP-PI-TRM', 'LP-PI-ALT-PTRM', 'LP-PI-BT-MD', 'LP-PI-BT-IZZI']

tgs.thing1.pars['magic_method_codes'], tgs.thing2.pars['magic_method_codes']
('LP-PI-BT-IZZI:IE-TT:LP-PI-ALT-PTRM:LP-PI-BT-MD', 'LP-PI-ZI:IE-TT:LP-PI-ALT-PTRM')



magic method codes:

LT-T-I	     Lab Treatment	Specimen cooling: In laboratory field

LP-PI-TRM    Lab Protocol		  	  Paleointensity experiment: Using a laboratory TRM. Any paleointensity experiment that uses a TRM produced in a lab controlled field. Includes all variants of the Thellier method, including the Shaw method. More details on alteration and reciprocity checks can be added using the special LP-PI-ALT and LP-PI-BT method codes. Thellier 1938.

LP-TRM	     Lab Protocol			 TRM acquisition.

LT-M-I	     Lab Treatment			Using microwave radiation: In laboratory field. Walton et al. 1993.

LP-PI-M	     Lab Protocol		       	Paleointensity experiment: Microwave demagnetization. 

LT-NO	     Lab Treatment			No treatments applied before measurement.

LT-T-Z	     Lab Treatment			Specimen cooling: In zero field. Heating the specimen to the desired temperature step and then cooling in zero ambient magnetic field. Wilson 1961, Collinson 1983.

LT-M-Z	     Lab Treatment			Using microwave radiation: In zero field. Walton et al. 1992.

LT-PTRM-Z    Lab Treatment			pTRM tail check After in laboratory field step, perform a zero field cooling at a lower temperature. After heating to a particular temperature step and cooling in field. The specimen is heated to a lower temperature step and cooled in zero field. This checks for low temperature pTRM tails. Harcombe-Smee et al. 1996.

LT-PTRM-I    Lab Treatment			 pTRM check: After zero field step, perform an in field cooling. After treatment at a particular temperature step, the specimen is then reheated to a lower temperature and cooled with the laboratory field on thus reapplying a pTRM. Coe 1967.

LT-PTRM-MD   Lab Treatment			       	     pTRM tail check: After in laboratory field step, perform a zero field cooling at same temperature. A check carried out during Thellier procedures to detect multidomain grains. Additional zero field heating steps are used to remove a previously placed pTRM. The ability to remove a prior pTRM step at the same temperature imparted is used as an indicator of reversal. Riisager & Riisager 2001, Scherbakov et al. 1993.




to do:

check get_curve()
      determine whether norming should or should not be done
ask Alex about last bit of VDS calculation
maybe return to delta_pal, although I think it is working
documentation
return to thellier_gui_spd editing.  definitely will want to rename, probably prune some unnecessary code
maybe go through stats one at a time, checking them against their definition?  but really, probably it's better just to get matlab
consider adding in a params checker so that you can actually run one statistic only.  or, run the stats in groups (by chapter)
problem with DRATS statistic.  maybe just because of the slightly different method of selecting ptrm checks in thellier_gui vs. spd.  inconsistency with specimen MGH1 # confirmed as suspected
check that new set of specimens are basically working correctly # DONE
AC checks now available in specimen_Data, however must attend to tmax
check for missing stats



cart2dir
	require x,y,z
dir2cart
	works with just Dec, Inc
	however, outputs very different value if given Dec, Inc, and m (or whatever)  magnitude is different
	dir2cart(Dec, Inc, 1) --> x,y,z
	dir2cart(Dec, Inc, 2) --> 2x,2y,z
	

thellier_gui Dec, Inc, and MAD are free.  lisa always uses free
matlab SVD and numpy SVD produce nearly, but not exactly, identical output.  difference is in V, and also in the format for S (less important) # seems to be a rounding issue only
Also, checked and numpy and matlab notation for slicing is the same, except that matlab indexing starts at 1, not 0



meeting with lisa:

need to figure out how we're doing testing.  I know matlab basic syntax now, but will need help parsing data to feed it into his code.  

architecture and use scenarios
	     paramater checking, to enable running just one statistic (with its dependencies)

abstracting out the parsing portion of thellier_gui_spd further




new meeting notes:

from greig's code:  % ChRM          - a (1 x 2) or a (1 x 3) vector describing an independent measure of the direction of Banc (can be a known direction).
this would make one of my stats wrong.  

how to do additivity

which chapter to stop at??



for meeting with Ron:

norming of points in curvature.  are they already normed?  I guess it just matters for magnitude


	This from thellier_gui is in contradiction to what's in spd.  this sometimes causes different results for pTRM check statistics
          # If triangle is within the interval but started after the upper temperature bound, then one pTRM check is in
cluded                                                                                                               
          # For example: if T_max=480, the traingle in 450 fall far, and it started at 500, then it is included  
          # the ateration occured between 450 and 500, we dont know when. 



delta_pal.  really pays no attention to tmin, just tmax?  weird.  check this.



projects for these times when you are missing information to actually work on your current project:

	 study Python
	 wx Python tutorial...(?) or possibly look at other gui frameworks
	 improve new_lj_thellier_gui_spd.  at least rename.
	 write a utility file that runs through all the tests....?  maybe this is unnecessary, though
	 remove unnecessary output for all files


to run all tests:

$  python -m unittest test_arai_plot_statistics test_directional_statistics test_curvature test_ptrm_statistics test_tail_check_statistics test_additivity_check_statistics



Python tips and tricks:

dir(spd) -- gives all methods/classes available in spd.  awesome.  

pop, remove, and del -- useful stuff for lists

*args

if changing a list in your loop, it's better to iterate through indices.  i.e, for i in range(len(lst)), vs for i in list

" ".join(row)

list comprehensions

filter() # takes two args, function and iterable.  works well with lambda.

lambda

overriding built in methods -- i.e., __repr__(), which determines how an object prints

you can use *args thusly:  
    a = [1,5]
    range(*a)


to use a list as a queue, use collections.dequeue, to grab off elements from the beginning of a list.  (for using a list as a stack, you can efficiently use append() and pop())



Notes for matlab:

struct is a dictionary(ish)
displays like this:
Params = 

               Xpts: [8x1 double]
               Ypts: [8x1 double]

called like this:
Params.Xpts


Think I sould make a script to write Params in an orderly manner to a tab-delimited file for easy comparison with 

cell array is similar to a Python list.  

my_struct = struct('a', 'b', 'c', 4)
	  a: b
	  c: 4
a = 'x'
my_struct.(a) == my_struct.x
my_struct.a == my_struct.a
isfield(my_struct, 'a') == 1 
fieldnames(my_struct) == [a, c]
orderfields, rmfields



my_cell = struct2cell(my_struct)
	'b'
	4



my_fieldnames = fieldnames(my_struct)
	      a
	      c


Restore data from a MAT-file into the workspace using load.  load myfile.mat.  also save myfile.mat puts workspace variables into a file


num2str -- number to string, obviously.  also int2str

my_cell(1) != my_cell{1}

my_cell(1) is a cell object of length one.  my_cell{1} is the first item	


next steps:
modify the read tdt program to be able to do more at one time
       probably best not to write to individual file, but all pile into one
check into data norming -- may be causing some of the discrepancies
maybe reduce rounding of greig's stuff so that you can do a more rigorous comparison.  
      rounding is all at line 1290 of getPintParams_v5c.m
the way comparisons work currently is if I only have one specimen and one sample with one specimen.  endeavering to fix that in lori_Read_TDT.m
    ./comp_files.py -f1 ET1_Biggin_2007_output_first.txt -f2 ~/Documents/MATLAB/new_out.out 
    works when only the BS file is available in the Data folder
    problem with the list in a list thing.  meh.




questions for Ron, next meeting:

pmag_criteria.txt
norming.... is this causing some of my problems?
some details about format of .tdt files
